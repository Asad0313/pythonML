{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc15321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Asad\n",
      "[nltk_data]     Ali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "language_stopwords = stopwords.words('english')\n",
    "non_words = list(punctuation)\n",
    "\n",
    "def remove_stop_words(dirty_text):\n",
    "\tcleaned_text = ''\n",
    "\tfor word in dirty_text.split():\n",
    "\t\tif word in language_stopwords or word in non_words:\n",
    "\t\t\tcontinue\n",
    "\t\telse:\n",
    "\t\t\tcleaned_text += word + ' '\n",
    "\treturn cleaned_text\n",
    "\n",
    "def remove_punctuation(dirty_string):\n",
    "\tfor word in non_words:\n",
    "\t\tdirty_string = dirty_string.replace(word, '')\n",
    "\treturn dirty_string\n",
    "\n",
    "def process_file(file_name):\n",
    "\tfile_content = open(file_name, \"r\").read()\n",
    "\t# All to lower case\n",
    "\tfile_content = file_content.lower()\n",
    "\t# Remove punctuation and spanish stopwords\n",
    "\tfile_content = remove_punctuation(file_content)\n",
    "\tfile_content = remove_stop_words(file_content)\n",
    "\treturn file_content\n",
    "\n",
    "# # nlp_article = process_file(\"macro1.txt\")\n",
    "# sentiment_analysis_article = process_file(\"macro1.txt\")\n",
    "# java_certification_article = process_file(\"macro1.txt\")\n",
    "\n",
    "# #TF-IDF\n",
    "# vectorizer = TfidfVectorizer ()\n",
    "# X = vectorizer.fit_transform([nlp_article,sentiment_analysis_article,java_certification_article])\n",
    "# #X = count.fit_transform([nlp_article,sentiment_analysis_article,java_certification_article])\n",
    "# similarity_matrix = cosine_similarity(X,X)\n",
    "\n",
    "# print('----------------------------------')\n",
    "# print('Leantechblog article similarity:')\n",
    "# print('----------------------------------')\n",
    "# print(similarity_matrix)\n",
    "\n",
    "# michelle_speech = process_file(\"macro1.txt\")\n",
    "# melania_speech = process_file(\"macro2.txt\")\n",
    "\n",
    "# #TF-IDF\n",
    "# vectorizer = TfidfVectorizer ()\n",
    "# X = vectorizer.fit_transform([michelle_speech,melania_speech])\n",
    "# similarity_matrix = cosine_similarity(X,X)\n",
    "\n",
    "\n",
    "# print(similarity_matrix[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9ca9524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.6.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cc8a9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>CASE NUMBER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Additional To: doultanirahul28@gmail.com CC: B...</td>\n",
       "      <td>156946126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Additional To: rider@foodpanda.pk CC: BCC: Att...</td>\n",
       "      <td>4-6qb7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Additional To: sidra.anum143@gmail.com CC: BCC...</td>\n",
       "      <td>156948385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Additional To: abdulwase@gmail.com CC: BCC: At...</td>\n",
       "      <td>156943359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Additional To: rider@foodpanda.pk CC: BCC: Att...</td>\n",
       "      <td>2wj-h5pm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6978</th>\n",
       "      <td>Additional To: asshhtaqvi@gmail.com CC: BCC: A...</td>\n",
       "      <td>157999002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6979</th>\n",
       "      <td>Additional To: salmanrashid438@gmail.com CC: B...</td>\n",
       "      <td>158003852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6980</th>\n",
       "      <td>Additional To: asadullah9@gmail.com CC: BCC: A...</td>\n",
       "      <td>158034527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6981</th>\n",
       "      <td>Additional To: rabia2r2@gmail.com CC: BCC: Att...</td>\n",
       "      <td>158041208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6982</th>\n",
       "      <td>Additional To: ayshajanat9@gmail.com CC: BCC: ...</td>\n",
       "      <td>158042491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6983 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Comments CASE NUMBER\n",
       "0     Additional To: doultanirahul28@gmail.com CC: B...   156946126\n",
       "1     Additional To: rider@foodpanda.pk CC: BCC: Att...     4-6qb7)\n",
       "2     Additional To: sidra.anum143@gmail.com CC: BCC...   156948385\n",
       "3     Additional To: abdulwase@gmail.com CC: BCC: At...   156943359\n",
       "4     Additional To: rider@foodpanda.pk CC: BCC: Att...   2wj-h5pm)\n",
       "...                                                 ...         ...\n",
       "6978  Additional To: asshhtaqvi@gmail.com CC: BCC: A...   157999002\n",
       "6979  Additional To: salmanrashid438@gmail.com CC: B...   158003852\n",
       "6980  Additional To: asadullah9@gmail.com CC: BCC: A...   158034527\n",
       "6981  Additional To: rabia2r2@gmail.com CC: BCC: Att...   158041208\n",
       "6982  Additional To: ayshajanat9@gmail.com CC: BCC: ...   158042491\n",
       "\n",
       "[6983 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = [\"Comments\", \"CASE NUMBER\"]\n",
    "df = pd.read_excel('C:\\\\Users\\\\Asad Ali\\\\Desktop\\\\plagirismchecking.xlsx',usecols=col_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aba1385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "x.extend(df['Comments'].tolist())\n",
    "y = []\n",
    "y.extend(df['CASE NUMBER'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fad05431",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_1 = []\n",
    "macro1 = process_file(\"macro1.txt\")\n",
    "for doc in x:\n",
    "    test = str(doc)\n",
    "    file_content = test.lower()\n",
    "    file_content = remove_punctuation(file_content)\n",
    "    file_content = remove_stop_words(file_content)\n",
    "    #TF-IDF\n",
    "    vectorizer = TfidfVectorizer ()\n",
    "    X = vectorizer.fit_transform([file_content,macro1])\n",
    "    #X = count.fit_transform([nlp_article,sentiment_analysis_article,java_certification_article])\n",
    "    similarity_matrix = cosine_similarity(X,X)\n",
    "    similarity_1.append(similarity_matrix[1,0] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7efbacf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_2 = []\n",
    "macro1 = process_file(\"macro2.txt\")\n",
    "for doc in x:\n",
    "    test = str(doc)\n",
    "    file_content = test.lower()\n",
    "    file_content = remove_punctuation(file_content)\n",
    "    file_content = remove_stop_words(file_content)\n",
    "    #TF-IDF\n",
    "    vectorizer = TfidfVectorizer ()\n",
    "    X = vectorizer.fit_transform([file_content,macro1])\n",
    "    #X = count.fit_transform([nlp_article,sentiment_analysis_article,java_certification_article])\n",
    "    similarity_matrix = cosine_similarity(X,X)\n",
    "    similarity_2.append(similarity_matrix[1,0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2626d3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_3 = []\n",
    "macro1 = process_file(\"macro3.txt\")\n",
    "for doc in x:\n",
    "    test = str(doc)\n",
    "    file_content = test.lower()\n",
    "    file_content = remove_punctuation(file_content)\n",
    "    file_content = remove_stop_words(file_content)\n",
    "    #TF-IDF\n",
    "    vectorizer = TfidfVectorizer ()\n",
    "    X = vectorizer.fit_transform([file_content,macro1])\n",
    "    #X = count.fit_transform([nlp_article,sentiment_analysis_article,java_certification_article])\n",
    "    similarity_matrix = cosine_similarity(X,X)\n",
    "    similarity_3.append(similarity_matrix[1,0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55f35864",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_4 = []\n",
    "macro1 = process_file(\"macro4.txt\")\n",
    "for doc in x:\n",
    "    test = str(doc)\n",
    "    file_content = test.lower()\n",
    "    file_content = remove_punctuation(file_content)\n",
    "    file_content = remove_stop_words(file_content)\n",
    "    #TF-IDF\n",
    "    vectorizer = TfidfVectorizer ()\n",
    "    X = vectorizer.fit_transform([file_content,macro1])\n",
    "    #X = count.fit_transform([nlp_article,sentiment_analysis_article,java_certification_article])\n",
    "    similarity_matrix = cosine_similarity(X,X)\n",
    "    similarity_4.append(similarity_matrix[1,0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a570139",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_5 = []\n",
    "macro1 = process_file(\"macro5.txt\")\n",
    "for doc in x:\n",
    "    test = str(doc)\n",
    "    file_content = test.lower()\n",
    "    file_content = remove_punctuation(file_content)\n",
    "    file_content = remove_stop_words(file_content)\n",
    "    #TF-IDF\n",
    "    vectorizer = TfidfVectorizer ()\n",
    "    X = vectorizer.fit_transform([file_content,macro1])\n",
    "    #X = count.fit_transform([nlp_article,sentiment_analysis_article,java_certification_article])\n",
    "    similarity_matrix = cosine_similarity(X,X)\n",
    "    similarity_5.append(similarity_matrix[1,0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17cd9a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_6 = []\n",
    "macro1 = process_file(\"macro6.txt\")\n",
    "for doc in x:\n",
    "    test = str(doc)\n",
    "    file_content = test.lower()\n",
    "    file_content = remove_punctuation(file_content)\n",
    "    file_content = remove_stop_words(file_content)\n",
    "    #TF-IDF\n",
    "    vectorizer = TfidfVectorizer ()\n",
    "    X = vectorizer.fit_transform([file_content,macro1])\n",
    "    #X = count.fit_transform([nlp_article,sentiment_analysis_article,java_certification_article])\n",
    "    similarity_matrix = cosine_similarity(X,X)\n",
    "    similarity_6.append(similarity_matrix[1,0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a10a83ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_7 = []\n",
    "macro1 = process_file(\"macro7.txt\")\n",
    "for doc in x:\n",
    "    test = str(doc)\n",
    "    file_content = test.lower()\n",
    "    file_content = remove_punctuation(file_content)\n",
    "    file_content = remove_stop_words(file_content)\n",
    "    #TF-IDF\n",
    "    vectorizer = TfidfVectorizer ()\n",
    "    X = vectorizer.fit_transform([file_content,macro1])\n",
    "    #X = count.fit_transform([nlp_article,sentiment_analysis_article,java_certification_article])\n",
    "    similarity_matrix = cosine_similarity(X,X)\n",
    "    similarity_7.append(similarity_matrix[1,0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30e13463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Email Body Case Number   \\\n",
      "0     Additional To: doultanirahul28@gmail.com CC: B...    156946126   \n",
      "1     Additional To: rider@foodpanda.pk CC: BCC: Att...      4-6qb7)   \n",
      "2     Additional To: sidra.anum143@gmail.com CC: BCC...    156948385   \n",
      "3     Additional To: abdulwase@gmail.com CC: BCC: At...    156943359   \n",
      "4     Additional To: rider@foodpanda.pk CC: BCC: Att...    2wj-h5pm)   \n",
      "...                                                 ...          ...   \n",
      "6978  Additional To: asshhtaqvi@gmail.com CC: BCC: A...    157999002   \n",
      "6979  Additional To: salmanrashid438@gmail.com CC: B...    158003852   \n",
      "6980  Additional To: asadullah9@gmail.com CC: BCC: A...    158034527   \n",
      "6981  Additional To: rabia2r2@gmail.com CC: BCC: Att...    158041208   \n",
      "6982  Additional To: ayshajanat9@gmail.com CC: BCC: ...    158042491   \n",
      "\n",
      "        Macro 1    Macro 2    Macro 3    Macro 4    Macro 5    Macro 6  \\\n",
      "0     11.378597    9.96646  10.174205  11.133693   9.155657   9.594168   \n",
      "1      10.12909  10.489051   9.378029  10.391886   9.943931   9.080006   \n",
      "2      8.799355  14.079471  12.331312   9.026199   13.31731  11.929567   \n",
      "3       9.23643  12.300301  11.105576   8.833843  11.253002  10.420418   \n",
      "4      7.088435   7.070688   5.881049   7.272342    6.70392   5.695423   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "6978   9.274537  10.913656   9.239887   8.998062  10.022069   8.691196   \n",
      "6979  12.534688  12.618382  10.165886  12.328844  11.654256   9.597168   \n",
      "6980   9.810129   11.93491  10.100559   9.515841   10.96456   9.504482   \n",
      "6981    8.78135   7.575649   7.830691   8.496069   6.902349   7.338424   \n",
      "6982  11.213914   9.811085    9.11596  11.015897   9.033561   8.599359   \n",
      "\n",
      "        Macro 7  \n",
      "0     10.330008  \n",
      "1      7.014793  \n",
      "2      9.030713  \n",
      "3      8.804514  \n",
      "4      4.825649  \n",
      "...         ...  \n",
      "6978   8.593255  \n",
      "6979  11.139759  \n",
      "6980   9.089504  \n",
      "6981   8.564522  \n",
      "6982  10.349275  \n",
      "\n",
      "[6983 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "data.append(x)\n",
    "data.append(y)\n",
    "data.append(similarity_1)\n",
    "data.append(similarity_2)\n",
    "data.append(similarity_3)\n",
    "data.append(similarity_4)\n",
    "data.append(similarity_5)\n",
    "data.append(similarity_6)\n",
    "data.append(similarity_7)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data).transpose()\n",
    "df.columns=['Email Body', 'Case Number ','Macro 1','Macro 2','Macro 3','Macro 4','Macro 5','Macro 6','Macro 7']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8683f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"final.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f51d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
